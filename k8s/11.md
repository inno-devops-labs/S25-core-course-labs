# Kubernetes Secrets and Hashicorp Vault

## Task 1

Creating an opaque secret from the commandline looks like this:

```bash
❯ kubectl create secret generic ropero-secret --from-literal=favourite_number=42
secret/ropero-secret created
```

To verify that the secret was created, we can get it:

```bash
❯ kubectl get secrets
NAME                                   TYPE                 DATA   AGE
ropero-secret                          Opaque               1      4s
sh.helm.release.v1.app-javascript.v1   helm.sh/release.v1   1      10d
sh.helm.release.v1.app-python.v1       helm.sh/release.v1   1      10d
sh.helm.release.v1.helm-hooks.v1       helm.sh/release.v1   1      10d
```

Here we can see that the top secret being the one we recently created. The last three were automatically 
created by helm in previous lab.

To decode the secret, we first need to get it in the crypted from (as a json object) and then decode it using base64:

```bash
❯ kubectl get secret ropero-secret -o jsonpath='{.data}'
{"favourite_number":"NDI="}%
❯ echo "NDI=" | base64 --decode
42%
```

Following the tutorial provided in the task, I created a `secrets.yaml` file outside using gpg, encrypting password
that is set to `secret1234`. Then, I modified the `secrets.yaml` in `templates` folder and added `env` in `deployment.yaml`,
where I gave password name `MY_PASSWORD`. After that, I restarted the helm installation while providing the outer `secrets.yaml`:

```bash
❯ helm secrets install app-python ./app-python -n default -f ./secrets.yaml
NAME: app-python
LAST DEPLOYED: Sun Mar  9 18:51:30 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
1. Get the application URL by running these commands:
  http://moscow-time-app.local/
removed './secrets.yaml.dec'
❯ kubectl get po
NAME                          READY   STATUS    RESTARTS   AGE
app-python-5fb496579b-6kdjb   1/1     Running   0          92s
app-python-5fb496579b-7vbkt   1/1     Running   0          92s
app-python-5fb496579b-twzrp   1/1     Running   0          92s
```

Now, we can check if the password is accessible from the inside of the pods (I will check the first one):

```bash
❯ kubectl exec app-python-5fb496579b-6kdjb -- printenv | grep MY_PASSWORD
MY_PASSWORD=secret1234
```

## Task 2

Installation of the vault:

```bash
❯ helm repo add hashicorp https://helm.releases.hashicorp.com
"hashicorp" has been added to your repositories
❯ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "hashicorp" chart repository
Update Complete. ⎈Happy Helming!⎈
❯ helm install vault hashicorp/vault --set "server.dev.enabled=true"
NAME: vault
LAST DEPLOYED: Sun Mar  9 19:23:33 2025
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
Thank you for installing HashiCorp Vault!

Now that you have deployed Vault, you should look over the docs on using
Vault with Kubernetes available here:

https://developer.hashicorp.com/vault/docs


Your release is named vault. To learn more about the release, try:

  $ helm status vault
  $ helm get manifest vault
❯ kubectl get pods
NAME                                    READY   STATUS    RESTARTS   AGE
app-python-5fb496579b-6kdjb             1/1     Running   0          32m
app-python-5fb496579b-7vbkt             1/1     Running   0          32m
app-python-5fb496579b-twzrp             1/1     Running   0          32m
vault-0                                 1/1     Running   0          26s
vault-agent-injector-66f45b5fd5-kdlvj   1/1     Running   0          28s
```

And setting the secret:

```bash
❯ kubectl exec -it vault-0 -- /bin/sh
/ $ vault secrets enable -path=internal kv-v2
Success! Enabled the kv-v2 secrets engine at: internal/
/ $ vault kv put internal/database/config username="ropero" password="admin"
======== Secret Path ========
internal/data/database/config

======= Metadata =======
Key                Value
---                -----
created_time       2025-03-09T16:27:29.246770613Z
custom_metadata    <nil>
deletion_time      n/a
destroyed          false
version            1
/ $ vault kv get internal/database/config
======== Secret Path ========
internal/data/database/config

======= Metadata =======
Key                Value
---                -----
created_time       2025-03-09T16:27:29.246770613Z
custom_metadata    <nil>
deletion_time      n/a
destroyed          false
version            1

====== Data ======
Key         Value
---         -----
password    admin
username    ropero
/ $ exit
```

The we configure kubernetes authentication:

```bash
❯ kubectl exec -it vault-0 -- /bin/sh
/ $ vault auth enable kubernetes
Success! Enabled kubernetes auth method at: kubernetes/
/ $ vault write auth/kubernetes/config \
> kubernetes_host="https://$KUBERNETES_PORT_443_TCP_ADDR:443"
Success! Data written to: auth/kubernetes/config
/ $ vault policy write internal-app - <<EOF
> path "internal/data/database/config" {
>    capabilities = ["read"]
> }
> EOF
Success! Uploaded policy: internal-app
/ $ vault write auth/kubernetes/role/internal-app \
>       bound_service_account_names=internal-app \
>       bound_service_account_namespaces=default \
>       policies=internal-app \
>       ttl=24h
Success! Data written to: auth/kubernetes/role/internal-app
```

The we create a service account:

```bash
❯ kubectl get serviceaccounts
NAME                   SECRETS   AGE
app-python             0         51m
default                0         11d
vault                  0         19m
vault-agent-injector   0         19m
❯ kubectl create sa internal-app
serviceaccount/internal-app created
❯ kubectl get serviceaccounts
NAME                   SECRETS   AGE
app-python             0         51m
default                0         11d
internal-app           0         10s
vault                  0         19m
vault-agent-injector   0         19m
```

Now we can apply patch that we wrote at `patch-inject-secrets.yaml`:

```bash
❯ kubectl patch deployment app-python --patch-file=./app-python/patch-inject-secrets.yaml
deployment.apps/app-python patched
```

And now we can enter out new, patched deployment with new id and check that everything worked:

```bash
❯ kubectl exec -it app-python-556f9774f4-l447d --container app-python -- /bin/sh
/app $ cat /vault/secrets/database-config.txt
data: map[password:admin username:ropero]
metadata: map[created_time:2025-03-09T17:52:35.042240814Z custom_metadata:<nil> deletion_time: destroyed:false version:1]
/app $ df -h
Filesystem                Size      Used Available Use% Mounted on
overlay                 936.8G    529.0G    360.2G  59% /
tmpfs                    64.0M         0     64.0M   0% /dev
shm                      64.0M         0     64.0M   0% /dev/shm
/dev/nvme0n1p2          936.8G    529.0G    360.2G  59% /dev/termination-log
tmpfs                    31.0G      4.0K     31.0G   0% /vault/secrets
/dev/nvme0n1p2          936.8G    529.0G    360.2G  59% /etc/resolv.conf
/dev/nvme0n1p2          936.8G    529.0G    360.2G  59% /etc/hostname
/dev/nvme0n1p2          936.8G    529.0G    360.2G  59% /etc/hosts
tmpfs                    31.0G     12.0K     31.0G   0% /run/secrets/kubernetes.io/serviceaccount
tmpfs                    15.5G         0     15.5G   0% /proc/asound
tmpfs                    15.5G         0     15.5G   0% /proc/acpi
tmpfs                    64.0M         0     64.0M   0% /proc/kcore
tmpfs                    64.0M         0     64.0M   0% /proc/keys
tmpfs                    64.0M         0     64.0M   0% /proc/timer_list
tmpfs                    15.5G         0     15.5G   0% /proc/scsi
tmpfs                    15.5G         0     15.5G   0% /sys/firmware
tmpfs                    15.5G         0     15.5G   0% /sys/devices/virtual/powercap
/app $ exit
```

## Bonus Task

Limiting resources is rather trivial - uncommenting the "resources" key in the `values.yaml` is enough (I decided not to adjust the values to the app as they aren't needy).
To introduce the environment variables both in helm and kuberenetes, we need to introduce them in `deployment.yaml` (tell it to look for `environmentVars` that we will define in helm),
define their default values in `values.yaml` and define the `environmentVars` themselves in `_helpers.tpl` (I called them env_var_NUMBER).

After of that is done, we get:

```bash
❯ kubectl describe deployments.apps app-python app-javascript
Name:                   app-python
Namespace:              default
CreationTimestamp:      Sun, 09 Mar 2025 21:32:33 +0300
Labels:                 app.kubernetes.io/instance=app-python
                        app.kubernetes.io/managed-by=Helm
                        app.kubernetes.io/name=app-python
                        app.kubernetes.io/version=1.16.0
                        helm.sh/chart=app-python-0.1.0
Annotations:            deployment.kubernetes.io/revision: 1
                        meta.helm.sh/release-name: app-python
                        meta.helm.sh/release-namespace: default
Selector:               app.kubernetes.io/instance=app-python,app.kubernetes.io/name=app-python
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:           app.kubernetes.io/instance=app-python
                    app.kubernetes.io/managed-by=Helm
                    app.kubernetes.io/name=app-python
                    app.kubernetes.io/version=1.16.0
                    helm.sh/chart=app-python-0.1.0
  Service Account:  internal-app
  Containers:
   app-python:
    Image:      gendiro/moscow-time-app:latest
    Port:       8000/TCP
    Host Port:  0/TCP
    Limits:
      cpu:     100m
      memory:  128Mi
    Requests:
      cpu:      100m
      memory:   128Mi
    Liveness:   http-get http://:http/ delay=0s timeout=1s period=10s #success=1 #failure=3
    Readiness:  http-get http://:http/ delay=0s timeout=1s period=10s #success=1 #failure=3
    Environment:
      FIRST_ENV_VAR:   first env variable
      SECOND_ENV_VAR:  second env variable
      THIRD_ENV_VAR:   third env variable
    Mounts:            <none>
  Volumes:             <none>
  Node-Selectors:      <none>
  Tolerations:         <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   app-python-764649f769 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  7m4s  deployment-controller  Scaled up replica set app-python-764649f769 from 0 to 3


Name:                   app-javascript
Namespace:              default
CreationTimestamp:      Sun, 09 Mar 2025 21:34:49 +0300
Labels:                 app.kubernetes.io/instance=app-javascript
                        app.kubernetes.io/managed-by=Helm
                        app.kubernetes.io/name=app-javascript
                        app.kubernetes.io/version=1.16.0
                        helm.sh/chart=app-javascript-0.1.0
Annotations:            deployment.kubernetes.io/revision: 1
                        meta.helm.sh/release-name: app-javascript
                        meta.helm.sh/release-namespace: default
Selector:               app.kubernetes.io/instance=app-javascript,app.kubernetes.io/name=app-javascript
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:           app.kubernetes.io/instance=app-javascript
                    app.kubernetes.io/managed-by=Helm
                    app.kubernetes.io/name=app-javascript
                    app.kubernetes.io/version=1.16.0
                    helm.sh/chart=app-javascript-0.1.0
  Service Account:  app-javascript
  Containers:
   app-javascript:
    Image:      gendiro/js-app-distroless:latest
    Port:       3000/TCP
    Host Port:  0/TCP
    Limits:
      cpu:     100m
      memory:  128Mi
    Requests:
      cpu:      100m
      memory:   128Mi
    Liveness:   http-get http://:http/ delay=0s timeout=1s period=10s #success=1 #failure=3
    Readiness:  http-get http://:http/ delay=0s timeout=1s period=10s #success=1 #failure=3
    Environment:
      FOURTH_ENV_VAR:  fourth env variable
      FIFTH_ENV_VAR:   fifth env variable
      SIXTH_ENV_VAR:   sixth env variable
    Mounts:            <none>
  Volumes:             <none>
  Node-Selectors:      <none>
  Tolerations:         <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   app-javascript-5d76fd4b46 (3/3 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  4m49s  deployment-controller  Scaled up replica set app-javascript-5d76fd4b46 from 0 to 3
```

As we can see, Env.variables and limits are there
