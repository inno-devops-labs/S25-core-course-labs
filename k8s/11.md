# Lab 11

## Task 1: Kubernetes Secrets and Resource Management

### 1. Create a Secret Using kubectl:

Firstly I start `minikube` with 

```bash
[root@laptop:/home/raleksan/projects/S25-core-course-labs/k8s]# minikube start --force
üòÑ  minikube v1.34.0 on Nixos 24.11
    ‚ñ™ MINIKUBE_WANTUPDATENOTIFICATION=false
‚ùó  minikube skips various validations when --force is supplied; this may lead to unexpected behavior
‚ú®  Using the docker driver based on existing profile
üõë  The "docker" driver should not be used with root privileges. If you wish to continue as root, use --force.
üí°  If you are running minikube within a VM, consider using --driver=none:
üìò    https://minikube.sigs.k8s.io/docs/reference/drivers/none/
üí°  Tip: To remove this root owned cluster, run: sudo minikube delete
üëç  Starting "minikube" primary control-plane node in "minikube" cluster
üöú  Pulling base image v0.0.45 ...
üèÉ  Updating the running docker "minikube" container ...
üê≥  Preparing Kubernetes v1.31.0 on Docker 27.2.0 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîó  Configuring bridge CNI (Container Networking Interface) ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Enabled addons: storage-provisioner, default-storageclass
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```

Create secret with:

```bash
kubectl create secret generic my-secret \
  --from-literal=username=admin \
  --from-literal=password=raleksan_admin_password
```

![Create secret](misc/lab11/1_create_secret.png)

### 2. Verify and Decode Your Secret:

- Get secret

```bash
kubectl get secret my-secret -o yaml
```

![Get secret](misc/lab11/2_get_secret.png)

- Decode secret

```bash
echo "<base64-encoded-password>" | base64 --decode
# or 
echo "cmFsZWtzYW5fYWRtaW5fcGFzc3dvcmQ=" | base64 --decode
```

![Decode secret from base 64](misc/lab11/3_decode_secret.png)

### 3. Manage Secrets with Helm:

To manage secrets with `Helm` I created following `templates/secrets.yaml`

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-helm-secret
type: Opaque
data:
  username: {{ .Values.secret.username | b64enc }}
  password: {{ .Values.secret.password | b64enc }}
```

and extend `templates/deployment.yaml`

```yaml
# Beginning part of config
env:
- name: MY_USERNAME
    valueFrom:
    secretKeyRef:
        name: my-helm-secret
        key: username
- name: MY_PASS
    valueFrom:
    secretKeyRef:
        name: my-helm-secret
        key: password
```

Now I can deploy `Helm` Chart:

```bash
helm install moscow-python moscow-time-python/ --set secret.username=$(echo -n "raleksan" | base64) --set secret.password=$(echo -n "are_you_sure" | base64)
```

![Helm secret](misc/lab11/4_helm_secret.png)

Extract `PASS` from deployment:

- Find pod name:

```bash
kubectl get pods
```

- Extract value

```bash
kubectl exec <pod-name> -- printenv | grep MY_PASS
# or
kubectl exec moscow-python-5c684f48c8-hwkgt -- printenv | grep MY_PASS
```

![Extract data](misc/lab11/5_helm_extract.png)


## Task 2: Vault Secret Management System

### 1. Install Vauilt

To install `Vault` to `Helm`:

- Add repo to `Helm`

```bash
helm repo add hashicorp https://helm.releases.hashicorp.com
```

- Install `Vault`:

```bash
helm install vault hashicorp/vault --set server.dev.enabled=true
```

Run commands:

![Install vault](misc/lab11/6_vault_install.png)

Show running pods:

![Vault pods](misc/lab11/7_vault_pods.png)


### 2. Follow the Tutorial with Your Helm Chart:

Add a secret to `Vault`

```bash
kubectl exec -it vault-0 -- vault kv put secret/my-secret username=raleksan password=are_you_sure
```

and configure authentication

```bash
kubectl exec -it vault-0 -- vault auth enable kubernetes
```

Run commands:

![Add secrets to vault](misc/lab11/8_vault_add_secret.png)

### 3. Implement Vault Secrets in Your Helm Chart:

To integrate `Vault` into `Helm` Chart:

- Update `values.yaml`:

```yaml
vault:
  enabled: true
  path: secret/my-secret
```

- Update `secrets.yaml`:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: vault-secrets
  annotations:
    vault.hashicorp.com/agent-inject: "true"
    vault.hashicorp.com/role: "internal-app"
    vault.hashicorp.com/agent-inject-secret-my-secret: "secret/my-secret"
    vault.hashicorp.com/agent-inject-secret-database-config.txt: "internal/data/database/config"
type: Opaque
data: {}
```

- Update `templates/deployment.yaml`:

```yaml
metadata:
  name: {{ .Release.Name }}
  labels:
    {{ include "my-library.labels" . | nindent 4 }}
  annotations:
    vault.hashicorp.com/agent-inject: "true"
    vault.hashicorp.com/agent-inject-secret-my-secret: "secret/my-secret"
```

- _Optional_: update `Helm` deployment:

```bash
helm upgrade moscow-python moscow-time-python/
```

- Explore vault inside pod:

```bash
kubectl exec -it <pod-name> -- cat /vault/secrets/my-secret
# or
kubectl exec -it moscow-python-5ccd578cbc-6qcp8 -- cat /vault/secrets/my-secret
```

I decided login to pods and run commands:

```bash
[root@laptop:/home/raleksan/projects/S25-core-course-labs/k8s]# kubectl exec -it moscow-python-5ccd578cbc-6qcp8 -- /bin/sh
Defaulted container "moscow-python" out of: moscow-python, vault-agent, vault-agent-init (init)

/moscow_python $ df -h
Filesystem                Size      Used Available Use% Mounted on
overlay                 451.7G     89.0G    339.7G  21% /
tmpfs                    64.0M         0     64.0M   0% /dev
tmpfs                   256.0M      4.0K    256.0M   0% /vault/secrets
/dev/sda3               451.7G     89.0G    339.7G  21% /dev/termination-log
/dev/sda3               451.7G     89.0G    339.7G  21% /etc/resolv.conf
/dev/sda3               451.7G     89.0G    339.7G  21% /etc/hostname
/dev/sda3               451.7G     89.0G    339.7G  21% /etc/hosts
shm                      64.0M         0     64.0M   0% /dev/shm
tmpfs                   256.0M     12.0K    256.0M   0% /run/secrets/kubernetes.io/serviceaccount
tmpfs                     7.8G         0      7.8G   0% /proc/asound
tmpfs                     7.8G         0      7.8G   0% /proc/acpi
tmpfs                    64.0M         0     64.0M   0% /proc/kcore
tmpfs                    64.0M         0     64.0M   0% /proc/keys
tmpfs                    64.0M         0     64.0M   0% /proc/timer_list
tmpfs                     7.8G         0      7.8G   0% /proc/scsi
tmpfs                     7.8G         0      7.8G   0% /sys/firmware

/moscow_python $ cat /vault/secrets/my-secret
username=raleksan
password=are_you_sure

```

## Bonus Task: Resource Management and Environment Variables

### 1. Set Up Requests and Limits for CPU and Memory for Both Helm Charts

I set same resourse limits for both applications through add lines to `values.yaml`:

```yaml
resources:
  limits:
    cpu: 100m
    memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi
```

and test setup:

```bash
[root@laptop:/home/raleksan/projects/S25-core-course-labs/k8s]# kubectl describe deployments.apps moscow-python | grep -A 10 Containers
  Containers:
   moscow-python:
    Image:      raleksan/app_python:v0.1
    Port:       8000/TCP
    Host Port:  0/TCP
    Limits:
      cpu:     100m
      memory:  128Mi
    Requests:
      cpu:      100m
      memory:   128Mi

[root@laptop:/home/raleksan/projects/S25-core-course-labs/k8s]# kubectl describe deployments.apps moscow-rust | grep -A 10 Containers
  Containers:
   moscow-rust:
    Image:      raleksan/app_rust:v0.1
    Port:       8000/TCP
    Host Port:  0/TCP
    Limits:
      cpu:     100m
      memory:  128Mi
    Requests:
      cpu:      100m
      memory:   128Mi
```

### 2. Add Environment Variables for Your Containers for Both Helm Charts

