## Components of Kube Prometheus Stack

1. Prometheus
Core metrics collector. Scrapes HTTP endpoints, stores time series data, uses PromQL for queries. Handles alert rules and evaluation.
2. Alertmanager
Processes alerts from Prometheus. Does deduplication, grouping, and routes notifications to channels (email, Slack). Provides silencing to reduce alert spam.
3. Grafana
Visualization tool. Connects to Prometheus and shows metrics in dashboards. Comes with pre-made templates but you can build custom ones too.
4. kube-state-metrics
Generates metrics about K8s objects (pods, deployments, nodes). Watches API and converts object data to metrics Prometheus can understand.
5. node-exporter
Runs as DaemonSet on all nodes. Collects hardware and OS metrics (CPU, memory, disk). Exposes HTTP endpoint that Prometheus scrapes.
6. Prometheus Operator
Manages Prometheus instances K8s-native way. Introduces custom resources (PrometheusRule, ServiceMonitor) for declarative config.
7. Prometheus Adapter
Implements K8s metrics API. Lets Prometheus metrics work with HPA for autoscaling. Translates between PromQL and metrics API.
8. Service/Pod Monitors
Custom resources from Prometheus Operator. Define which services/pods to monitor and how to scrape them. More K8s-way than traditional Prometheus config.

## Helm Charts Installation Results

```bash
dm@DESKTOP-85MKAD8:/mnt/d/github_repos/S25-core-course-labs$ kubectl get po,sts,svc,pvc,cm -n monitoring
```

```text
NAME                                                         READY   STATUS    RESTARTS   AGE
pod/alertmanager-monitoring-kube-prometheus-alertmanager-0   2/2     Running   0          9m37s
pod/monitoring-grafana-7fb77bbddd-94lwt                      3/3     Running   0          10m
pod/monitoring-kube-prometheus-operator-67859c588b-2hb8m     1/1     Running   0          10m
pod/monitoring-kube-state-metrics-c86996f4f-75vtq            1/1     Running   0          10m
pod/monitoring-prometheus-node-exporter-pzpd9                1/1     Running   0          10m
pod/prometheus-monitoring-kube-prometheus-prometheus-0       2/2     Running   0          9m37s

NAME                                                                    READY   AGE
statefulset.apps/alertmanager-monitoring-kube-prometheus-alertmanager   1/1     9m37s
statefulset.apps/prometheus-monitoring-kube-prometheus-prometheus       1/1     9m37s

NAME                                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)
   AGE
service/alertmanager-operated                     ClusterIP   None             <none>        9093/TCP,9094/TCP,9094/UDP   9m37s
service/monitoring-grafana                        ClusterIP   10.108.90.203    <none>        80/TCP
   10m
service/monitoring-kube-prometheus-alertmanager   ClusterIP   10.109.210.71    <none>        9093/TCP,8080/TCP
   10m
service/monitoring-kube-prometheus-operator       ClusterIP   10.107.78.165    <none>        443/TCP
   10m
service/monitoring-kube-prometheus-prometheus     ClusterIP   10.97.42.166     <none>        9090/TCP,8080/TCP
   10m
service/monitoring-kube-state-metrics             ClusterIP   10.97.145.239    <none>        8080/TCP
   10m
service/monitoring-prometheus-node-exporter       ClusterIP   10.108.147.239   <none>        9100/TCP
   10m
service/prometheus-operated                       ClusterIP   None             <none>        9090/TCP
   9m37s

NAME                                                                     DATA   AGE
configmap/kube-root-ca.crt                                               1      12m
configmap/monitoring-grafana                                             1      10m
configmap/monitoring-grafana-config-dashboards                           1      10m
configmap/monitoring-kube-prometheus-alertmanager-overview               1      10m
configmap/monitoring-kube-prometheus-apiserver                           1      10m
configmap/monitoring-kube-prometheus-cluster-total                       1      10m
configmap/monitoring-kube-prometheus-controller-manager                  1      10m
configmap/monitoring-kube-prometheus-etcd                                1      10m
configmap/monitoring-kube-prometheus-grafana-datasource                  1      10m
configmap/monitoring-kube-prometheus-grafana-overview                    1      10m
configmap/monitoring-kube-prometheus-k8s-coredns                         1      10m
configmap/monitoring-kube-prometheus-k8s-resources-cluster               1      10m
configmap/monitoring-kube-prometheus-k8s-resources-multicluster          1      10m
configmap/monitoring-kube-prometheus-k8s-resources-namespace             1      10m
configmap/monitoring-kube-prometheus-k8s-resources-node                  1      10m
configmap/monitoring-kube-prometheus-k8s-resources-pod                   1      10m
configmap/monitoring-kube-prometheus-k8s-resources-workload              1      10m
configmap/monitoring-kube-prometheus-k8s-resources-workloads-namespace   1      10m
configmap/monitoring-kube-prometheus-kubelet                             1      10m
configmap/monitoring-kube-prometheus-namespace-by-pod                    1      10m
configmap/monitoring-kube-prometheus-namespace-by-workload               1      10m
configmap/monitoring-kube-prometheus-node-cluster-rsrc-use               1      10m
configmap/monitoring-kube-prometheus-node-rsrc-use                       1      10m
configmap/monitoring-kube-prometheus-nodes                               1      10m
configmap/monitoring-kube-prometheus-nodes-darwin                        1      10m
configmap/monitoring-kube-prometheus-persistentvolumesusage              1      10m
configmap/monitoring-kube-prometheus-pod-total                           1      10m
configmap/monitoring-kube-prometheus-prometheus                          1      10m
configmap/monitoring-kube-prometheus-proxy                               1      10m
configmap/monitoring-kube-prometheus-scheduler                           1      10m
configmap/monitoring-kube-prometheus-workload-total                      1      10m
configmap/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0   35     9m37s
```

### Pods

**alertmanager** (2/2) - Processes and routes alerts based on rules, handles notifications to email/Slack/etc.

**grafana** (3/3) - Provides visualization dashboards for metrics with graphs and charts

**prometheus-operator** (1/1) - Controls Prometheus instances using Kubernetes custom resources

**kube-state-metrics** (1/1) - Generates metrics about Kubernetes objects (pods, deployments, etc.)

**node-exporter** (1/1) - Collects hardware and OS metrics from cluster nodes

**prometheus** (2/2) - Scrapes, stores and processes all metrics data; core monitoring engine

### StatefulSets

**alertmanager** (1/1) - Maintains persistent alert manager with stateful configuration

**prometheus** (1/1) - Ensures persistent storage and stable identity for Prometheus database

### Services

**alertmanager-operated** - Internal service for alertmanager component communication

**monitoring-grafana** - Exposes Grafana web interface for user access

**monitoring-kube-prometheus-alertmanager** - External access to alertmanager UI

**monitoring-kube-prometheus-operator** - Secure API endpoint for operator configuration

**monitoring-kube-prometheus-prometheus** - Access to Prometheus query interface and API

**monitoring-kube-state-metrics** - Endpoint where Prometheus scrapes K8s state metrics

**monitoring-prometheus-node-exporter** - Endpoint for node hardware metrics collection

**prometheus-operated** - Headless service for Prometheus StatefulSet pods

### ConfigMaps

**Multiple dashboard definitions** - Pre-configured visualizations for different aspects of cluster

**Component configurations** - Settings for each monitoring component

**Prometheus rule files** - Contains 35 alert definitions and recording rules

All components work together to provide complete monitoring pipeline


## Grafana Dashboard Exploration Results

### 1. StatefulSet CPU/Memory consumption
From "Kubernetes / Compute Resources / Namespace (Workloads)":
- CPU: prometheus StatefulSet uses ~0.03 cores (3% of allocated)
- Memory: prometheus StatefulSet uses ~489.58 MiB

### 2. Pods CPU usage in default namespace
From "Kubernetes / Compute Resources / Node (Pods)":
- Highest CPU: kube-apiserver (~0.14 cores, 57.43% of requests)
- Lowest CPU: coredns (~0.01 cores, 5.01% of requests)

### 3. Node memory usage
From "Node Exporter / Nodes" dashboard:
- Percentage: 44.8% utilization 
- Megabytes: ~9.31 GiB total with ~4.17 GiB used

### 4. Kubelet managed resources
From "Kubernetes / Kubelet" dashboard:
- Pods running: 14
- Containers: 22
- Volumes: 52

### 5. Network usage of Pods
In "Kubernetes / Networking / Cluster":
- kube-system: 1.80 kB/s receive, 2.87 kB/s transmit
- monitoring: 60.86 kB/s receive, 18.43 kB/s transmit

### 6. Active alerts
In "Alertmanager / Overview" dashboard:
- Active alerts: 0 (all good)
- No notification send rates to any channels




## Task 2: Init Containers

### Implementation

I created a Pod with an Init Container that downloads a file using wget:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-demo
spec:
  volumes:
  - name: shared-data
    emptyDir: {}
  initContainers:
  - name: download-file
    image: busybox
    command: ['wget', '-O', '/data/test.html', 'http://info.cern.ch/hypertext/WWW/TheProject.html']
    volumeMounts:
    - name: shared-data
      mountPath: /data
  containers:
  - name: main-app
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 3600; done']
    volumeMounts:
    - name: shared-data
      mountPath: /data
```

This Pod configuration:
1. Creates a shared volume named `shared-data` using the emptyDir type
2. Defines an Init Container that uses wget to download the first-ever WWW page
3. Mounts the shared volume at /data to store the downloaded file
4. Has a main container that keeps running and can access the same volume

### Proof of Success

After applying the YAML manifest, I verified that the Init Container successfully downloaded the file:

```bash
$ kubectl exec init-container-demo -- cat /data/test.html
Defaulted container "main-app" out of: main-app, download-file (init)
<HEADER>
<TITLE>The World Wide Web project</TITLE>
<NEXTID N="55">
</HEADER>
<BODY>
<H1>World Wide Web</H1>The WorldWideWeb (W3) is a wide-area<A
NAME=0 HREF="WhatIs.html">
hypermedia</A> information retrieval
initiative aiming to give universal
access to a large universe of documents.<P>
Everything there is online about
W3 is linked directly or indirectly
to this document, including an <A
NAME=24 HREF="Summary.html">executive
summary</A> of the project, <A
NAME=29 HREF="Administration/Mailing/Overview.html">Mailing lists</A>
, <A
NAME=30 HREF="Policy.html">Policy</A> , November's  <A
NAME=34 HREF="News/9211.html">W3  news</A> ,
<A
NAME=41 HREF="FAQ/List.html">Frequently Asked Questions</A> .
...
```

The output confirms that:
1. The Init Container has finished its job and terminated
2. The main container has started and is running
3. The file was successfully downloaded and stored in the shared volume
4. We can access the file from the main container



## Bonus Task 1: App Metrics

### Fetching Metrics from Node Exporter

I verified that metrics are being collected by querying Prometheus through its web interface:

```
node_memory_MemTotal_bytes{container="node-exporter", endpoint="http-metrics", instance="192.168.49.2:9100", job="node-exporter", namespace="monitoring", pod="monitoring-prometheus-node-exporter-pzpd9", service="monitoring-prometheus-node-exporter"}
```

This query returns the total memory of my Minikube node as reported by node-exporter, with the following labels:
- `container="node-exporter"` - The container collecting hardware metrics
- `endpoint="http-metrics"` - The endpoint exposing the metrics
- `instance="192.168.49.2:9100"` - The IP and port of the node-exporter
- `job="node-exporter"` - The Prometheus job name
- `namespace="monitoring"` - The namespace where node-exporter is running
- `pod="monitoring-prometheus-node-exporter-pzpd9"` - The name of the pod
- `service="monitoring-prometheus-node-exporter"` - The service exposing node-exporter

This returns total memory on my Minikube node. The query shows Prometheus successfully collects metrics from node-exporter, proving monitoring works correctly.

## Bonus Task 2: Init Container Queue

### Implementation of Multiple Init Containers

Created a pod with three init containers that sequentially add lines to the same file:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-init-container-demo
spec:
  volumes:
  - name: shared-data
    emptyDir: {}
  initContainers:
  - name: init-container-1
    image: busybox
    command: ['sh', '-c', 'echo "Line 1: Added by first init container" > /data/multi-init.txt']
    volumeMounts:
    - name: shared-data
      mountPath: /data
  - name: init-container-2
    image: busybox
    command: ['sh', '-c', 'echo "Line 2: Added by second init container" >> /data/multi-init.txt']
    volumeMounts:
    - name: shared-data
      mountPath: /data
  - name: init-container-3
    image: busybox
    command: ['sh', '-c', 'echo "Line 3: Added by third init container" >> /data/multi-init.txt']
    volumeMounts:
    - name: shared-data
      mountPath: /data
  containers:
  - name: main-app
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 3600; done']
    volumeMounts:
    - name: shared-data
      mountPath: /data
```

### Proof of Execution

After running, I verified all three containers executed properly:

```bash
$ kubectl exec multi-init-container-demo -- cat /data/multi-init.txt
Defaulted container "main-app" out of: main-app, init-container-1 (init), init-container-2 (init), init-container-3 (init)
Line 1: Added by first init container
Line 2: Added by second init container
Line 3: Added by third init container
```

The output confirms all init containers ran in sequence and each added its line to the shared file.
