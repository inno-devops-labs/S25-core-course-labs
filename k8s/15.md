# Lab 15: Kubernetes Monitoring and Init Containers

## Task 1: Kubernetes Cluster Monitoring with Prometheus

### Kube Prometheus Stack Components

The Kube Prometheus Stack is a collection of Kubernetes manifests, Grafana dashboards, and Prometheus rules that provide easy monitoring definitions for Kubernetes clusters. Here's a breakdown of its key components:

1. **Prometheus Operator**:
   - The core component that manages Prometheus instances
   - Creates, configures, and manages Prometheus monitoring instances
   - Automatically generates monitoring target configurations based on Kubernetes label queries
   - Simplifies the deployment and configuration of Prometheus in Kubernetes environments

2. **Prometheus**:
   - The actual time-series database and monitoring system
   - Collects and stores metrics as time-series data
   - Provides a powerful query language (PromQL) for data analysis
   - Implements a pull-based model where it scrapes metrics from configured targets
   - Supports alerting based on metric thresholds

3. **Alertmanager**:
   - Handles alerts sent by Prometheus
   - Deduplicates, groups, and routes alerts to the correct receiver
   - Supports various notification methods (email, Slack, PagerDuty, etc.)
   - Implements silencing and inhibition mechanisms to reduce alert noise

4. **Node Exporter**:
   - Collects hardware and OS metrics from the Kubernetes nodes
   - Exposes system metrics like CPU usage, memory, disk I/O, and network statistics
   - Runs as a DaemonSet to ensure it's present on every node in the cluster

5. **kube-state-metrics**:
   - Generates metrics about the state of Kubernetes objects
   - Monitors the state of various Kubernetes objects (Pods, Deployments, Nodes, etc.)
   - Provides insights into the health and performance of the Kubernetes cluster itself
   - Complements the metrics provided by Kubelet and the Kubernetes API server

6. **Grafana**:
   - Visualization platform for metrics and logs
   - Provides a rich UI for creating dashboards and visualizing Prometheus metrics
   - Comes pre-configured with dashboards for Kubernetes monitoring
   - Supports alerting based on metric thresholds

7. **Service Monitors and Pod Monitors**:
   - Custom resources defined by the Prometheus Operator
   - Define which services and pods should be monitored by Prometheus
   - Allow for declarative configuration of monitoring targets

8. **PrometheusRules**:
   - Custom resources for defining alerting and recording rules
   - Enable the creation of complex alerting conditions
   - Allow for the pre-computation of frequently used or complex expressions

This stack provides a comprehensive monitoring solution for Kubernetes clusters, offering insights into both the infrastructure (nodes, network) and the applications running on it (pods, services). The components work together to collect, store, analyze, visualize, and alert on metrics, creating a complete monitoring pipeline.

## Task 1 (continued): Kubernetes Cluster Monitoring with Prometheus

### Output of `kubectl get po,sts,svc,pvc,cm` Command

```
NAME                                                          READY   STATUS             RESTARTS   AGE
pod/app-python-python-app-0                                   0/1     ErrImagePull       0          40s
pod/app-python-python-app-1                                   0/1     ErrImagePull       0          40s
pod/app-python-python-app-2                                   0/1     ErrImagePull       0          40s
pod/app-python-python-app-5cc6f7c685-4xwml                    0/1     ImagePullBackOff   0          40s
pod/app-python-python-app-5cc6f7c685-fx8r5                    0/1     ErrImagePull       0          40s
pod/app-python-python-app-5cc6f7c685-tzjrc                    0/1     ErrImagePull       0          40s
pod/helm-hooks-example-moscow-time-app-dc5946c98-5ztsx        0/1     ImagePullBackOff   1          22d
pod/helm-hooks-example-moscow-time-app-post-install-example   0/1     Completed          0          22d
pod/helm-hooks-example-moscow-time-app-pre-install-example    0/1     Completed          0          22d
pod/helm-hooks-moscow-time-app-5d4fcfc74f-6jpd9               0/1     ImagePullBackOff   1          22d
pod/moscow-time-api-56d97f7c6d-29slv                          0/1     ImagePullBackOff   1          22d
pod/moscow-time-api-56d97f7c6d-tkl2t                          0/1     ImagePullBackOff   1          22d
pod/moscow-time-api-56d97f7c6d-tkn88                          0/1     ErrImagePull       1          22d
pod/moscow-time-moscow-time-app-794cfc6b74-fnrxg              0/1     ErrImagePull       1          22d

NAME                                     READY   AGE
statefulset.apps/app-python-python-app   0/3     40s

NAME                                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE
service/app-python-python-app                ClusterIP   None             <none>        80/TCP                          40s
service/helm-hooks-example-moscow-time-app   NodePort    10.105.148.70    <none>        8001:31375/TCP8000:32094/TCP   22d
service/helm-hooks-moscow-time-app           NodePort    10.108.7.70      <none>        8001:32201/TCP8000:31382/TCP   22d
service/kubernetes                           ClusterIP   10.96.0.1        <none>        443/TCP                         22d
service/moscow-time-api                      NodePort    10.110.251.95    <none>        8001:31894/TCP8000:31925/TCP   22d
service/moscow-time-moscow-time-app          NodePort    10.111.138.238   <none>        8001:32550/TCP8000:31153/TCP   22d

NAME                                                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/data-app-python-python-app-0   Bound    pvc-fa65c534-5d4f-442c-89c8-a112ceb1adc2   1Gi        RWO            standard       <unset>                 40s
persistentvolumeclaim/data-app-python-python-app-1   Bound    pvc-f579f27b-2289-4829-845a-0359316f6d34   1Gi        RWO            standard       <unset>                 40s
persistentvolumeclaim/data-app-python-python-app-2   Bound    pvc-af730296-9e2d-49cc-aa74-f17ca420f0b2   1Gi        RWO            standard       <unset>                 40s

NAME                         DATA   AGE
configmap/kube-root-ca.crt   1      22d
```

#### Explanation of the Output:

1. **Pods (po)**:
   - `app-python-python-app-0`, `app-python-python-app-1`, `app-python-python-app-2`: These are the pods created by the StatefulSet. They are currently in an `ErrImagePull` state, which means Kubernetes is having trouble pulling the container image.
   - `app-python-python-app-5cc6f7c685-4xwml`, `app-python-python-app-5cc6f7c685-fx8r5`, `app-python-python-app-5cc6f7c685-tzjrc`: These are pods created by a Deployment. They are also having image pull issues.
   - Various other pods from previous deployments are also listed, some in `ImagePullBackOff` or `ErrImagePull` states, and some in `Completed` state (for the hook pods).

2. **StatefulSets (sts)**:
   - `app-python-python-app`: This is our StatefulSet with 3 replicas, but currently none are ready (0/3).

3. **Services (svc)**:
   - `app-python-python-app`: A headless service (ClusterIP: None) for our StatefulSet, exposing port 80.
   - `kubernetes`: The default service for the Kubernetes API server.
   - Various other services from previous deployments, mostly of type NodePort, exposing different ports.

4. **Persistent Volume Claims (pvc)**:
   - `data-app-python-python-app-0`, `data-app-python-python-app-1`, `data-app-python-python-app-2`: These are the PVCs created for each pod in the StatefulSet. They are all bound to volumes with 1Gi capacity and ReadWriteOnce (RWO) access mode.

5. **ConfigMaps (cm)**:
   - `kube-root-ca.crt`: The default ConfigMap containing the root CA certificate for the Kubernetes cluster.

### Grafana Dashboard Information

Based on the Grafana dashboards, here are the answers to the questions:

1. **CPU and Memory consumption of the StatefulSet**:
   - The StatefulSet pods (app-python-python-app-0, app-python-python-app-1, app-python-python-app-2) have very low CPU usage, approximately 0.00 cores.
   - Memory utilization is also minimal, with values around 0.299% from requests and 0.150% from limits.

2. **Pods with higher and lower CPU usage in the default namespace**:
   - All pods in the default namespace have relatively low CPU usage.
   - The pods with slightly higher CPU usage are the app-python-python-app pods, but the difference is minimal.
   - The CPU Usage graph shows values around 0.0632% from requests and 0.0316% from limits.

3. **Node memory usage in percentage and megabytes**:
   - The memory usage is approximately 954 MiB.
   - The memory usage graph shows usage without cache.
   - The maximum capacity is shown as 1.40 GiB.

4. **Number of pods and containers managed by the Kubelet service**:
   - There are 29 running pods.
   - There are 29 running containers.
   - There is 1 running Kubelet.
   - The actual volume count is 73, matching the desired volume count.

5. **Network usage of Pods in the default namespace**:
   - Network usage information is not clearly visible in the provided dashboards.

6. **Number of active alerts**:
   - There are approximately 2 active alerts based on the Alertmanager Overview dashboard.
   - The alerts graph shows a recent increase in alerts.

## Task 2: Init Containers

For this task, I've implemented an Init Container that downloads a file using wget. Here's the implementation:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-demo
  labels:
    app: init-container-demo
spec:
  volumes:
    - name: shared-volume
      emptyDir: {}
  containers:
    - name: main-container
      image: busybox
      command: ['sh', '-c', 'while true; do echo "Main container is running"; sleep 30; done']
      volumeMounts:
        - name: shared-volume
          mountPath: /data
  initContainers:
    - name: init-download
      image: busybox
      command: ['wget', '-O', '/data/test.html', 'http://info.cern.ch/hypertext/WWW/TheProject.html']
      volumeMounts:
        - name: shared-volume
          mountPath: /data
```

This configuration:
1. Creates a shared volume using `emptyDir`.
2. Defines an Init Container that uses wget to download the HTML file from CERN (the first web page ever created).
3. Mounts the shared volume to both the Init Container and the main container.
4. The main container can access the downloaded file after the Init Container completes successfully.

Proof of successful download:
```
$ kubectl exec init-container-demo -- cat /data/test.html | head -n 5
Defaulted container "main-container" out of: main-container init-download (init)
<HEADER>
<TITLE>The World Wide Web project</TITLE>
<NEXTID N="55">
</HEADER>
<BODY>
```

## Bonus Task: App Metrics & Multiple Init Containers

### Multiple Init Containers

I've implemented a queue of three Init Containers, each adding a new line to the same file:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-queue-demo
  labels:
    app: init-container-queue-demo
spec:
  volumes:
    - name: shared-volume
      emptyDir: {}
  containers:
    - name: main-container
      image: busybox
      command: ['sh', '-c', 'while true; do echo "Main container is running"; sleep 30; done']
      volumeMounts:
        - name: shared-volume
          mountPath: /data
  initContainers:
    - name: init-container-1
      image: busybox
      command: ['sh', '-c', 'echo "Line added by Init Container 1" > /data/shared-file.txt']
      volumeMounts:
        - name: shared-volume
          mountPath: /data
    - name: init-container-2
      image: busybox
      command: ['sh', '-c', 'echo "Line added by Init Container 2" >> /data/shared-file.txt']
      volumeMounts:
        - name: shared-volume
          mountPath: /data
    - name: init-container-3
      image: busybox
      command: ['sh', '-c', 'echo "Line added by Init Container 3" >> /data/shared-file.txt']
      volumeMounts:
        - name: shared-volume
          mountPath: /data
```

Proof of successful execution:
```
$ kubectl exec init-container-queue-demo -- cat /data/shared-file.txt
Defaulted container "main-container" out of: main-container init-container-1 (init) init-container-2 (init) init-container-3 (init)
Line added by Init Container 1
Line added by Init Container 2
Line added by Init Container 3
```

This demonstrates how Init Containers run sequentially, with each container waiting for the previous one to complete before starting. The main container only starts after all Init Containers have successfully completed.
