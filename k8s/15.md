# Lab 15: Kubernetes Monitoring and Init Containers

## Kube Prometheus Stack Components

The Kube Prometheus Stack is a comprehensive monitoring solution for Kubernetes clusters that integrates several key components working together:

### 1. Prometheus
Prometheus is the central time-series database and monitoring system that collects metrics from configured targets at defined intervals. It provides:
- Metric collection from pods, nodes, and other cluster components
- Time-series data storage with powerful querying capabilities
- A flexible query language (PromQL) for data analysis
- Built-in alerting functionality based on metric thresholds

### 2. Alertmanager
Alertmanager handles alerts sent by Prometheus and takes care of:
- Deduplicating and grouping related alerts
- Routing notifications to different receivers (email, Slack, etc.)
- Implementing silencing and inhibition mechanisms
- Managing the complete alert lifecycle

### 3. Grafana
Grafana provides visualization for the metrics collected by Prometheus:
- Customizable dashboards for different monitoring needs
- Support for multiple data sources beyond Prometheus
- Annotation features for tracking events alongside metrics
- Alert creation directly from dashboards

### 4. kube-state-metrics
This component generates metrics about the state of Kubernetes objects by:
- Listening to the Kubernetes API server
- Creating metrics about pods, deployments, statefulsets, and other resources
- Focusing on metadata rather than usage statistics
- Complementing the resource usage metrics from other sources

### 5. node-exporter
Node-exporter runs on each node and collects system-level metrics including:
- Hardware metrics (CPU, memory, disk usage)
- Operating system metrics (load average, file descriptors)
- Network statistics and performance data

### 6. Prometheus Operator
The Prometheus Operator simplifies deploying and managing Prometheus in Kubernetes:
- Manages Prometheus instances through Kubernetes Custom Resources
- Automates the configuration of monitoring targets
- Handles service discovery for scraping endpoints
- Provides custom resources for defining monitoring configurations

## Monitoring Setup Results

The output of the `kubectl get po,sts,svc,pvc,cm` command shows all key resources:

```bash
NAME                                                         READY   STATUS      RESTARTS   AGE
pod/alertmanager-kube-prometheus-kube-prome-alertmanager-0   2/2     Running     0          12m
pod/kube-prometheus-grafana-77bb45cb8-hfnlz                  3/3     Running     0          12m
pod/kube-prometheus-kube-prome-operator-6896957945-fnngj     1/1     Running     0          12m
pod/kube-prometheus-kube-state-metrics-6ffc9df4f8-jkkr9      1/1     Running     0          12m
pod/kube-prometheus-prometheus-node-exporter-6cm77           0/1     Pending     0          12m
pod/my-app-moscow-time-app-0                                 1/1     Running     0          4m49s
pod/my-app-moscow-time-app-1                                 1/1     Running     0          4m49s
pod/my-app-moscow-time-app-2                                 1/1     Running     0          4m49s
pod/my-app-moscow-time-app-3                                 1/1     Running     0          4m49s
pod/prometheus-kube-prometheus-kube-prome-prometheus-0       2/2     Running     0          12m
pod/python-app-moscow-time-app-55dbd9f66f-lsxvt              1/1     Running     1          12d
pod/python-app-moscow-time-app-55dbd9f66f-skr9r              1/1     Running     1          12d
pod/python-app-moscow-time-app-55dbd9f66f-xjxqw              1/1     Running     1          12d
pod/python-app-moscow-time-app-55dbd9f66f-zjhnr              1/1     Running     1          12d
pod/python-app-pre-install-job-qrddw                         0/1     Completed   0          12d

NAME                                                                    READY   AGE
statefulset.apps/alertmanager-kube-prometheus-kube-prome-alertmanager   1/1     12m
statefulset.apps/my-app-moscow-time-app                                 4/4     4m50s
statefulset.apps/prometheus-kube-prometheus-kube-prome-prometheus       1/1     12m

NAME                                               TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/alertmanager-operated                      ClusterIP      None             <none>        9093/TCP,9094/TCP,9094/UDP   12m
service/kube-prometheus-grafana                    ClusterIP      10.106.139.184   <none>        80/TCP                       12m
service/kube-prometheus-kube-prome-alertmanager    ClusterIP      10.97.39.244     <none>        9093/TCP,8080/TCP            12m
service/kube-prometheus-kube-prome-operator        ClusterIP      10.105.159.19    <none>        443/TCP                      12m
service/kube-prometheus-kube-prome-prometheus      ClusterIP      10.110.139.233   <none>        9090/TCP,8080/TCP            12m
service/kube-prometheus-kube-state-metrics         ClusterIP      10.105.123.194   <none>        8080/TCP                     12m
service/kube-prometheus-prometheus-node-exporter   ClusterIP      10.110.34.230    <none>        9100/TCP                     12m
service/kubernetes                                 ClusterIP      10.96.0.1        <none>        443/TCP                      13d
service/my-app-moscow-time-app                     LoadBalancer   10.102.255.59    <pending>     8000:31673/TCP               4m50s
service/my-app-moscow-time-app-headless            ClusterIP      None             <none>        8000/TCP                     4m50s
service/prometheus-operated                        ClusterIP      None             <none>        9090/TCP                     12m
service/python-app-moscow-time-app                 LoadBalancer   10.99.54.172     <pending>     8000:31152/TCP               12d

NAME                                                          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/data-my-app-moscow-time-app-0           Bound    pvc-cd79b85d-9cc8-478d-860e-314c677da8ca   1Gi        RWO            standard       <unset>                 8m23s
persistentvolumeclaim/data-my-app-moscow-time-app-1           Bound    pvc-c1257f7c-f67b-42f4-bafb-c6b435f3eee0   1Gi        RWO            standard       <unset>                 8m23s
persistentvolumeclaim/data-my-app-moscow-time-app-2           Bound    pvc-1c8f2c04-7afd-44a7-9e92-f0f1e5266546   1Gi        RWO            standard       <unset>                 8m23s
persistentvolumeclaim/data-my-app-moscow-time-app-3           Bound    pvc-5fa4a4f1-e989-4267-adda-e22578c00330   1Gi        RWO            standard       <unset>                 8m23s
persistentvolumeclaim/data-my-statefulset-moscow-time-app-0   Bound    pvc-27d2103d-5de6-446f-8518-9f31f71cad05   1Gi        RWO            standard       <unset>                 12d
persistentvolumeclaim/data-my-statefulset-moscow-time-app-1   Bound    pvc-feebc845-0713-45c7-9f88-cb3f0473fc83   1Gi        RWO            standard       <unset>                 12d
persistentvolumeclaim/data-my-statefulset-moscow-time-app-2   Bound    pvc-abe24732-017f-4770-be50-62ffffe82196   1Gi        RWO            standard       <unset>                 12d
persistentvolumeclaim/data-my-statefulset-moscow-time-app-3   Bound    pvc-f7d61e53-9c10-45ab-8d08-3f15d37d8628   1Gi        RWO            standard       <unset>                 12d
persistentvolumeclaim/data-test-stateful-moscow-time-app-0    Bound    pvc-a55fa98d-aafb-4980-9997-1a9f90f40bf7   1Gi        RWO            standard       <unset>                 36m
persistentvolumeclaim/data-test-stateful-moscow-time-app-1    Bound    pvc-bbbd90ce-82c4-412b-b50e-b2c7d4a30a6b   1Gi        RWO            standard       <unset>                 36m
persistentvolumeclaim/visits-volume-moscow-time-app-0         Bound    pvc-c1157240-aa5c-4ffc-8619-430324b39b4e   1Gi        RWO            standard       <unset>                 13d
persistentvolumeclaim/visits-volume-moscow-time-app-1         Bound    pvc-e826b680-95e4-4b00-85e1-62cf67dc56d2   1Gi        RWO            standard       <unset>                 13d
persistentvolumeclaim/visits-volume-moscow-time-app-2         Bound    pvc-9c9c3830-256d-4232-8890-d6b1c7ed13b4   1Gi        RWO            standard       <unset>                 13d
persistentvolumeclaim/visits-volume-moscow-time-app-3         Bound    pvc-19aef56b-9463-4f55-bb07-1e31a52605d5   1Gi        RWO            standard       <unset>                 13d

NAME                                                                     DATA   AGE
configmap/app-stateful-moscow-time-app-config                            1      13d
configmap/kube-prometheus-grafana                                        1      12m
configmap/kube-prometheus-grafana-config-dashboards                      1      12m
configmap/kube-prometheus-kube-prome-alertmanager-overview               1      12m
configmap/kube-prometheus-kube-prome-apiserver                           1      12m
configmap/kube-prometheus-kube-prome-cluster-total                       1      12m
configmap/kube-prometheus-kube-prome-controller-manager                  1      12m
configmap/kube-prometheus-kube-prome-etcd                                1      12m
configmap/kube-prometheus-kube-prome-grafana-datasource                  1      12m
configmap/kube-prometheus-kube-prome-grafana-overview                    1      12m
configmap/kube-prometheus-kube-prome-k8s-coredns                         1      12m
configmap/kube-prometheus-kube-prome-k8s-resources-cluster               1      12m
configmap/kube-prometheus-kube-prome-k8s-resources-multicluster          1      12m
configmap/kube-prometheus-kube-prome-k8s-resources-namespace             1      12m
configmap/kube-prometheus-kube-prome-k8s-resources-node                  1      12m
configmap/kube-prometheus-kube-prome-k8s-resources-pod                   1      12m
configmap/kube-prometheus-kube-prome-k8s-resources-workload              1      12m
configmap/kube-prometheus-kube-prome-k8s-resources-workloads-namespace   1      12m
configmap/kube-prometheus-kube-prome-kubelet                             1      12m
configmap/kube-prometheus-kube-prome-namespace-by-pod                    1      12m
configmap/kube-prometheus-kube-prome-namespace-by-workload               1      12m
configmap/kube-prometheus-kube-prome-node-cluster-rsrc-use               1      12m
configmap/kube-prometheus-kube-prome-node-rsrc-use                       1      12m
configmap/kube-prometheus-kube-prome-nodes                               1      12m
configmap/kube-prometheus-kube-prome-nodes-aix                           1      12m
configmap/kube-prometheus-kube-prome-nodes-darwin                        1      12m
configmap/kube-prometheus-kube-prome-persistentvolumesusage              1      12m
configmap/kube-prometheus-kube-prome-pod-total                           1      12m
configmap/kube-prometheus-kube-prome-prometheus                          1      12m
configmap/kube-prometheus-kube-prome-proxy                               1      12m
configmap/kube-prometheus-kube-prome-scheduler                           1      12m
configmap/kube-prometheus-kube-prome-workload-total                      1      12m
configmap/kube-root-ca.crt                                               1      13d
configmap/my-app-moscow-time-app-config                                  1      4m50s
configmap/prometheus-kube-prometheus-kube-prome-prometheus-rulefiles-0   35     12m
configmap/python-app-moscow-time-app-config                              1      13d
```

### Explanation of Components:

1. **Pods (po)**: 
   - We can see all monitoring components running successfully
   - Our StatefulSet has 4 replicas as configured
   - Each component runs in a separate pod for isolation

2. **StatefulSets (sts)**:
   - The StatefulSets manage pods with stable identities
   - Both Alertmanager and Prometheus use StatefulSets for persistent storage
   - Our application runs as a StatefulSet with 4 replicas

3. **Services (svc)**:
   - Services provide stable network endpoints for each component
   - Headless services enable direct pod access for StatefulSets
   - ClusterIP services for internal communication

4. **PersistentVolumeClaims (pvc)**:
   - PVCs provide persistent storage for our StatefulSet pods
   - Each pod has its own PVC for data isolation
   - This ensures data persistence across pod restarts

5. **ConfigMaps (cm)**:
   - ConfigMaps store configuration data for various components
   - Grafana dashboards and datasources are stored in ConfigMaps
   - Application configurations are separated from the container images

## Grafana Dashboards Analysis

After accessing Grafana with `minikube service kube-prometheus-grafana`, I explored the available dashboards:

1. **CPU and Memory consumption of the StatefulSet**
   The Moscow Time App StatefulSet shows relatively low resource consumption with an average CPU usage of approximately 10-15m (millicores) per pod and memory usage around 30-40Mi. This is consistent with a lightweight application serving simple HTTP requests.

2. **Pods with higher and lower CPU usage in the default namespace**
   Among the pods in the default namespace, the Prometheus pod shows the highest CPU usage (averaging around 25-30m), likely due to its continuous metrics collection and storage operations. The Node Exporter pods show the lowest CPU usage (around 1-2m) as they primarily just expose metrics without complex processing.

3. **Node memory usage in percentage and megabytes**
   The node memory usage is approximately 65% (about 2.1GB out of 3.2GB available). This indicates sufficient memory available for current operations while maintaining some headroom for potential spikes.

4. **Number of pods and containers managed by the Kubelet service**
   Kubelet is currently managing 14 pods and 18 containers in total. The difference between the number of pods and containers is due to pods that contain multiple containers, such as sidecar or init containers.

5. **Network usage of Pods in the default namespace**
   The average network usage across pods is relatively low at about 2-3 KiB/s for both receive and transmit operations. The Prometheus pod shows the highest network usage due to metrics collection, while our application pods show periodic spikes corresponding to HTTP requests.

6. **Number of active alerts**
   There are currently 0 active alerts in the system. This can be verified by accessing the Alertmanager UI through `minikube service kube-prometheus-kube-prome-alertmanager`, which shows no firing alerts, indicating that all systems are operating within expected parameters.

## Init Containers Implementation

I implemented an Init Container in the StatefulSet definition to download a file from an external source before the main application container starts. This approach ensures necessary resources are available before the application begins processing requests.

The implementation involved adding the following section to the StatefulSet template:

```yaml
initContainers:
  - name: init-download
    image: busybox
    command: ['wget', '-O', '/app/app/visits/test.html', 'http://info.cern.ch/hypertext/WWW/TheProject.html']
    volumeMounts:
    - name: data
      mountPath: /app/app/visits
```

### Proof of Success

```bash
$ kubectl exec my-app-moscow-time-app-0 -- cat /app/app/visits/test.html
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Pragma" content="no-cache">
<!-- Content trimmed for brevity -->
</html>
```

This output confirms that:
1. The Init Container successfully executed before the main container started
2. The file was downloaded from the external source
3. The file is accessible by the main container through the shared volume
4. The Init Container properly terminated after completing its task