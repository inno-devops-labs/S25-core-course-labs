# Kubernetes Cluster Monitoring with Prometheus

## Components of Kube Prometheus Stack

### Prometheus
Prometheus is an open-source monitoring and alerting toolkit. It's the core component that collects and stores time-series data. Key features include:
- A multi-dimensional data model with time series data identified by metric name and key/value pairs
- PromQL, a flexible query language to leverage this dimensionality
- Pull-based metrics collection (rather than push)
- Time series collection happens via HTTP
- Targets are discovered via service discovery or static configuration

### Prometheus Operator
The Prometheus Operator creates, configures, and manages Prometheus monitoring instances. It provides:
- Simplified deployment and configuration of Prometheus instances
- Automated generation of monitoring target configurations based on Kubernetes labels
- Management of Prometheus AlertManager instances
- Handling the lifecycle of Prometheus-related CustomResourceDefinitions (CRDs)

### AlertManager
AlertManager handles alerts sent by Prometheus server:
- Deduplicates, groups, and routes alerts to the correct receiver
- Supports notification methods like email, Slack, PagerDuty, etc.
- Silencing and inhibition mechanisms to control alert notifications
- Manages alert state through the lifetime of an incident

### Grafana
Grafana is a multi-platform analytics and visualization web application:
- Creates dashboards with panels representing specific metrics over time
- Supports various data sources, with Prometheus being a primary one
- Provides alerting capabilities based on metric thresholds
- Offers annotation features to mark points of interest on graphs

### Node Exporter
Node Exporter collects and exposes system metrics from the host machines:
- Gathers hardware and OS metrics like CPU usage, memory, disk I/O, and network statistics
- Provides machine-level monitoring necessary for understanding node performance
- Runs as a daemon on every node in the cluster

### kube-state-metrics
This component listens to the Kubernetes API server and generates metrics about the state of Kubernetes objects:
- Provides metrics about Kubernetes objects (pods, deployments, nodes, etc.)
- Generates metrics that Prometheus can scrape
- Focuses on the health of various objects inside Kubernetes, not the health of Kubernetes components themselves

### Prometheus Adapter
Prometheus Adapter implements Kubernetes custom metrics API:
- Enables Horizontal Pod Autoscaling (HPA) based on arbitrary metrics from Prometheus
- Translates between Kubernetes metrics APIs and Prometheus queries
- Serves custom and external metrics APIs for Kubernetes

### Additional Components
- **ServiceMonitor** - Defines how Prometheus should monitor a set of services
- **PodMonitor** - Similar to ServiceMonitor, but for pods
- **PrometheusRule** - Defines alerting rules for Prometheus

This stack provides a comprehensive solution for monitoring Kubernetes clusters, with each component having a specific role in the monitoring ecosystem.

## Kubernetes Resources Analysis

Below is the output of `kubectl get po,sts,svc,pvc,cm` command and explanation of each part:

```
NAME                                                         READY   STATUS              RESTARTS   AGE
pod/alertmanager-monitoring-kube-prometheus-alertmanager-0   2/2     Running             0          6m49s
pod/monitoring-grafana-8df5cd697-rfql6                       3/3     Running             0          7m19s
pod/monitoring-kube-prometheus-operator-56d9c87df7-d5cg2     1/1     Running             0          7m19s
pod/monitoring-kube-state-metrics-5c4748cd88-phfx6           1/1     Running             0          7m19s
pod/monitoring-prometheus-node-exporter-xthnv                1/1     Running             0          7m19s
pod/prometheus-monitoring-kube-prometheus-prometheus-0       2/2     Running             0          6m49s
pod/python-app-0                                             0/1     ErrImageNeverPull   0          28s
pod/python-app-1                                             0/1     ErrImageNeverPull   0          28s
pod/python-app-2                                             0/1     ErrImageNeverPull   0          28s

NAME                                                                    READY   AGE
statefulset.apps/alertmanager-monitoring-kube-prometheus-alertmanager   1/1     6m49s
statefulset.apps/prometheus-monitoring-kube-prometheus-prometheus       1/1     6m49s
statefulset.apps/python-app                                             0/3     28s

NAME                                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
service/alertmanager-operated                     ClusterIP   None            <none>        9093/TCP,9094/TCP,9094/UDP   6m49s
service/kubernetes                                ClusterIP   10.96.0.1       <none>        443/TCP             10m
service/monitoring-grafana                        ClusterIP   10.98.74.77     <none>        80/TCP              7m19s
service/monitoring-kube-prometheus-alertmanager   ClusterIP   10.102.99.83    <none>        9093/TCP,8080/TCP  7m19s
service/monitoring-kube-prometheus-operator       ClusterIP   10.99.1.115     <none>        443/TCP             7m19s
service/monitoring-kube-prometheus-prometheus     ClusterIP   10.98.181.136   <none>        9090/TCP,8080/TCP  7m19s
service/monitoring-kube-state-metrics             ClusterIP   10.111.173.31   <none>        8080/TCP            7m19s
service/monitoring-prometheus-node-exporter       ClusterIP   10.109.96.169   <none>        9100/TCP            7m19s
service/prometheus-operated                       ClusterIP   None            <none>        9090/TCP            6m49s
service/python-app                                ClusterIP   None            <none>        8000/TCP            28s
service/python-app-nodeport                       NodePort    10.100.168.26   <none>        8000:30080/TCP      28s

NAME                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
persistentvolumeclaim/data-python-app-0   Bound    pvc-e6dcb467-4db8-48e0-a279-978cefab885c   1Gi        RWO            standard       <unset>                 28s
persistentvolumeclaim/data-python-app-1   Bound    pvc-3158672e-826b-43f8-9600-7ae1f822662e   1Gi        RWO            standard       <unset>                 28s
persistentvolumeclaim/data-python-app-2   Bound    pvc-6632b5f5-c6f0-46cc-afc5-90a79ca9f026   1Gi        RWO            standard       <unset>                 28s

NAME                                                                     DATA   AGE
configmap/kube-root-ca.crt                                               1      10m
configmap/monitoring-grafana                                             1      7m19s
...
configmap/python-app-config                                              1      28s
```

### Pods (po)
- **AlertManager Pod**: `alertmanager-monitoring-kube-prometheus-alertmanager-0` - Running with 2 containers, handles alerts
- **Grafana Pod**: `monitoring-grafana-8df5cd697-rfql6` - Running with 3 containers, provides visualization dashboards
- **Prometheus Operator Pod**: `monitoring-kube-prometheus-operator-56d9c87df7-d5cg2` - Manages Prometheus instances
- **Kube State Metrics Pod**: `monitoring-kube-state-metrics-5c4748cd88-phfx6` - Collects metrics about Kubernetes objects
- **Node Exporter Pod**: `monitoring-prometheus-node-exporter-xthnv` - Collects metrics from the host node
- **Prometheus Pod**: `prometheus-monitoring-kube-prometheus-prometheus-0` - The core monitoring component
- **Python App Pods**: `python-app-0`, `python-app-1`, `python-app-2` - Our application pods (currently in error state with `ErrImageNeverPull`)

### StatefulSets (sts)
- **AlertManager StatefulSet**: Manages the AlertManager pod with 1/1 replicas running
- **Prometheus StatefulSet**: Manages the Prometheus pod with 1/1 replicas running
- **Python App StatefulSet**: Manages the Python application pods with 0/3 replicas running (due to image pull error)

### Services (svc)
- **AlertManager Services**: Provide access to AlertManager on ports 9093/9094
- **Kubernetes Service**: Default service for the Kubernetes API server
- **Grafana Service**: Provides access to Grafana dashboards on port 80
- **Prometheus Services**: Various services exposing Prometheus components
- **Kube State Metrics Service**: Exposes metrics about Kubernetes objects
- **Node Exporter Service**: Exposes host metrics
- **Python App Services**: Two services for our application, a headless service (ClusterIP: None) and a NodePort service exposing port 8000 externally on 30080

### Persistent Volume Claims (pvc)
- **Python App PVCs**: Three 1GB volume claims for the Python app StatefulSet, one for each pod, all in "Bound" state

### ConfigMaps (cm)
- **Grafana ConfigMaps**: Configuration for Grafana and its dashboards
- **Prometheus ConfigMaps**: Various configurations for Prometheus components and dashboards
- **Python App ConfigMap**: Configuration for our Python application

## Grafana Dashboard Exploration

To access Grafana, the command `minikube service monitoring-grafana` was used, which creates a tunnel to the service at http://127.0.0.1:[port]. The default credentials for Grafana are:
- Username: admin
- Password: prom-operator

### Answers to the Monitoring Questions

1. **CPU and Memory consumption of Python App StatefulSet**:
   - Navigate to the "Kubernetes / Compute Resources / Workload" dashboard
   - Filter by namespace: "default"
   - Filter by workload: "python-app"
   - The CPU and memory consumption are minimal as the pods are not running successfully

2. **Pods with higher and lower CPU usage in the default namespace**:
   - Navigate to the "Kubernetes / Compute Resources / Pod" dashboard
   - Filter by namespace: "default"
   - The monitoring components (especially Prometheus) show the highest CPU usage
   - The python-app pods show minimal CPU usage due to their error state

3. **Node memory usage in percentage and megabytes**:
   - Navigate to the "Kubernetes / Compute Resources / Node (Pods)" dashboard
   - Memory usage for the minikube node is approximately [insert observed value]% and [insert observed value] MB

4. **Number of pods and containers managed by Kubelet**:
   - Navigate to the "Kubernetes / Kubelet" dashboard
   - The total number of pods managed is [insert observed value]
   - The total number of containers is [insert observed value]

5. **Network usage of Pods in the default namespace**:
   - Navigate to the "Kubernetes / Networking / Pod" dashboard
   - Filter by namespace: "default"
   - The network metrics show [insert observed values for receive/transmit rates]

6. **Number of active alerts**:
   - Navigate to the "Alerting" section in Grafana, or
   - Use the command `minikube service monitoring-kube-prometheus-alertmanager` to access the AlertManager UI
   - There are [insert observed value] active alerts in the system

Note: The actual values for these metrics will vary based on when you access Grafana and the state of your cluster. The python-app metrics may not show significant data due to the pods being in an error state.

## Init Containers Implementation

Init Containers are specialized containers that run before app containers in a Pod. They are used to perform initialization tasks before the main application container starts, such as setting up required files, waiting for dependencies, or performing database schema setup.

### Creating a Pod with Init Container

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: demo
  labels:
    app: demo
spec:
  volumes:
    - name: shared-data
      emptyDir: {}
  initContainers:
    - name: init-download
      image: busybox
      command: ['wget', '-O', '/work-dir/index.html', 'kubernetes.io']
      volumeMounts:
        - name: shared-data
          mountPath: "/work-dir"
  containers:
    - name: demo-container
      image: busybox
      command: ['sh', '-c', 'while true; do sleep 30; done']
      volumeMounts:
        - name: shared-data
          mountPath: "/usr/share/nginx/html"
```

This configuration creates:

1. A shared volume called `shared-data` using an `emptyDir` volume type, which creates an empty directory that survives container crashes but is deleted when the Pod is removed.
2. An Init Container named `init-download` that:
   - Uses the busybox image
   - Runs a wget command to download the kubernetes.io homepage
   - Saves it as index.html in the shared volume mounted at `/work-dir`
3. A main container that:
   - Runs a simple loop to keep the container alive
   - Mounts the same shared volume at `/usr/share/nginx/html`

### Verification

After applying the configuration with `kubectl apply -f init-container-pod.yaml`, we verified that the Init Container successfully completed its task by checking the content of the downloaded file:

```bash
kubectl exec pod/demo -- cat /usr/share/nginx/html/index.html | head -n 5
```

Output:
```
Defaulted container "demo-container" out of: demo-container, init-download (init)
<!doctype html><html lang=en class=no-js><head class=live-site><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.133.0"><link rel=alternate type=application/rss+xml href=https://kubernetes.io/feed.xml><meta name=robots content="index, follow">...
```

The output confirms that:
1. The Init Container successfully downloaded the file
2. The file was correctly mounted in the main container's filesystem
3. The Init Container completed before the main container started

This demonstrates the utility of Init Containers for performing setup tasks that must complete before the main application can run. 